Automated Report Generation using an In-House LLM

Overview
ReMach is a locally hosted Large Language Model (LLM)-powered report generator that processes Excel files to extract insights. It is designed for organizations that require AI-driven data analysis without relying on external APIs, ensuring data privacy and security.

Features
âœ… In-House LLM â€“ Runs on Ollama, eliminating cloud dependency
âœ… FastAPI Backend â€“ Efficient API for processing user queries
âœ… Streamlit UI â€“ Simple web-based interface for file uploads & reports
âœ… Excel Processing â€“ Uses Pandas & OpenPyXL for handling structured data
âœ… Lightweight & Scalable â€“ Works on minimal computational resources

How It Works
Upload an Excel File ğŸ“‚ (Containing structured data & questions)

FastAPI processes the file ğŸ“Š (Extracts tabular data & queries)

Ollama LLM generates insights ğŸ’¡ (Based on the extracted data)

Download the generated report ğŸ“œ (With AI-driven answers)

Tech Stack
Backend: FastAPI

Frontend: Streamlit

LLM Framework: Ollama (Locally hosted DeepSeek model)

Data Processing: Pandas, OpenPyXL

Deployment: Self-hosted on internal infrastructure

Installation & Setup
Prerequisites
Ensure you have the following installed:
ğŸ”¹ Python 3.9+
ğŸ”¹ Ollama (for local LLM hosting) â€“ Install from Ollamaâ€™s official site
ğŸ”¹ Virtual Environment (Recommended)

Demo
ğŸ–¥ï¸ Upload an Excel file containing:

Sheet 1: Table Data

Sheet 2: List of Questions

ğŸ“Š The system will analyze the table and provide AI-generated answers.

Use Cases
âœ… Business Intelligence â€“ Automate data analysis & insights generation
âœ… Market Research â€“ Extract trends from structured datasets
âœ… Enterprise Analytics â€“ In-house AI-driven reports without cloud costs

License
ğŸ“œ MIT License â€“ Free to modify and use for commercial & personal projects.


