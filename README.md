Automated Report Generation using an In-House LLM

Overview
ReMach is a locally hosted Large Language Model (LLM)-powered report generator that processes Excel files to extract insights. It is designed for organizations that require AI-driven data analysis without relying on external APIs, ensuring data privacy and security.

Features
âœ… In-House LLM â€“ Runs on Ollama, eliminating cloud dependency
âœ… FastAPI Backend â€“ Efficient API for processing user queries
âœ… Streamlit UI â€“ Simple web-based interface for file uploads & reports
âœ… Excel Processing â€“ Uses Pandas & OpenPyXL for handling structured data
âœ… Lightweight & Scalable â€“ Works on minimal computational resources

How It Works
Upload an Excel File ðŸ“‚ (Containing structured data & questions)

FastAPI processes the file ðŸ“Š (Extracts tabular data & queries)

Ollama LLM generates insights ðŸ’¡ (Based on the extracted data)

Download the generated report ðŸ“œ (With AI-driven answers)

Tech Stack
Backend: FastAPI

Frontend: Streamlit

LLM Framework: Ollama (Locally hosted DeepSeek model)

Data Processing: Pandas, OpenPyXL

Deployment: Self-hosted on internal infrastructure

Installation & Setup
Prerequisites
Ensure you have the following installed:
ðŸ”¹ Python 3.9+
ðŸ”¹ Ollama (for local LLM hosting) â€“ Install from Ollamaâ€™s official site
ðŸ”¹ Virtual Environment (Recommended)
